{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apart from body, id\n",
    "# Reddit          : title, score           : 195K jokes\n",
    "# Wocka           : category, title        : 10.0K jokes\n",
    "# Stupidstuff     : category, rating       : 3.77 K jokes\n",
    "\n",
    "# Considering just Wocka and stupid stuff because we need category for classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the dataset such that we have only body, id, category from wocka and stupid stuff\n",
    "\n",
    "# Header files\n",
    "import json\n",
    "\n",
    "# Reading data\n",
    "jsonFile1 = open('wocka.json', 'r')\n",
    "values1 = json.load(jsonFile1)\n",
    "jsonFile2 = open('stupidstuff.json', 'r')\n",
    "values2 = json.load(jsonFile2)\n",
    "\n",
    "# Combining only the rows that have body, id, category to one file\n",
    "def get_data(values1, combined_json_data):\n",
    "    for line in values1:\n",
    "        if (line['category']):\n",
    "            single_joke = {}\n",
    "            # Getting the category and joke id\n",
    "            single_joke['category'] = line['category']\n",
    "            single_joke['id'] = line['id']\n",
    "            \n",
    "            # Removing the \\n \\rs from the joke body\n",
    "            joke = \"\"\n",
    "            joke = line['body'].replace('\\r', '')\n",
    "            joke = joke.replace('\\n', '')\n",
    "            joke = joke.replace('\\\"', '')\n",
    "            single_joke['joke'] = joke\n",
    "            #single_joke = json.dumps(single_joke)\n",
    "            \n",
    "            combined_json_data.append(single_joke)\n",
    "    return (combined_json_data)\n",
    "\n",
    "combined_json_data = get_data(values1, [])\n",
    "combined_json_data = get_data(values2, combined_json_data)\n",
    "\n",
    "# Dumping it to a json file 'jokes_with_categories.json'\n",
    "with open('jokes_with_categories.json', 'w') as json_file:  \n",
    "    json.dump(combined_json_data, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points: 13792\n",
      "Average length of joke in terms number of words: 107\n",
      "\n",
      "\n",
      "Classes details\n",
      "(u'Gross', 254)\n",
      "(u'Light Bulbs', 120)\n",
      "(u'Farmers', 29)\n",
      "(u'Food Jokes', 13)\n",
      "(u'English', 1)\n",
      "(u'Knock-Knock', 167)\n",
      "(u'Science', 18)\n",
      "(u'Sports', 195)\n",
      "(u'Idiots', 31)\n",
      "(u'Love & Romance', 48)\n",
      "(u'Music', 9)\n",
      "(u'Animal', 656)\n",
      "(u'Crazy Jokes', 43)\n",
      "(u'Holidays', 69)\n",
      "(u'Miscellaneous', 831)\n",
      "(u'Marriage', 37)\n",
      "(u'Ethnic Jokes', 8)\n",
      "(u'Business', 104)\n",
      "(u'Men', 190)\n",
      "(u'News / Politics', 279)\n",
      "(u'One Liners', 945)\n",
      "(u'Insults', 472)\n",
      "(u'Men / Women', 925)\n",
      "(u'Yo Momma', 600)\n",
      "(u'Redneck', 268)\n",
      "(u'Animals', 131)\n",
      "(u'Aviation', 35)\n",
      "(u'Blonde Jokes', 111)\n",
      "(u'Women', 144)\n",
      "(u'School', 62)\n",
      "(u'Other / Misc', 2305)\n",
      "(u'Bar', 154)\n",
      "(u'Blond', 598)\n",
      "(u'Political', 141)\n",
      "(u'Medical', 309)\n",
      "(u'Old Age', 22)\n",
      "(u'Lawyers', 50)\n",
      "(u'Tech', 151)\n",
      "(u'At Work', 288)\n",
      "(u'Office Jokes', 18)\n",
      "(u'Military', 58)\n",
      "(u'Yo Mama', 144)\n",
      "(u'State Jokes', 10)\n",
      "(u'Lightbulb', 110)\n",
      "(u'Police Jokes', 67)\n",
      "(u'Blind Jokes', 11)\n",
      "(u'Bar Jokes', 87)\n",
      "(u'Money', 82)\n",
      "(u'Heaven and Hell', 91)\n",
      "(u'Computers', 150)\n",
      "(u'Sex', 54)\n",
      "(u'College', 131)\n",
      "(u'Deep Thoughts', 14)\n",
      "(u'Lawyer', 157)\n",
      "(u'Family, Parents', 96)\n",
      "(u'Puns', 457)\n",
      "(u'Blonde', 1)\n",
      "(u'Religious', 554)\n",
      "(u'Children', 687)\n"
     ]
    }
   ],
   "source": [
    "# Data set details\n",
    "\n",
    "\n",
    "# Total number of data points\n",
    "print \"Total number of data points: \" + str(len(combined_json_data))\n",
    "\n",
    "\n",
    "# Average length of the body/joke, shortest, longest\n",
    "# The total number of categories and how many data points they have\n",
    "import collections\n",
    "with open('jokes_with_categories.json') as f:\n",
    "    json_data = json.load(f)\n",
    "tot_length = []\n",
    "classes_dict = collections.defaultdict(int)\n",
    "for single_data in json_data:\n",
    "    tot_length.append(len(single_data['joke'].strip().split(\" \")))\n",
    "    classes_dict[single_data['category']] += 1  \n",
    "\n",
    "print \"Average length of joke in terms number of words: \"+ str(sum(tot_length)/len(tot_length))\n",
    "print \"\\n\\nClasses details\"\n",
    "\n",
    "for k, v in classes_dict.items():\n",
    "    print(k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a logistic regression with Tfidf \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
